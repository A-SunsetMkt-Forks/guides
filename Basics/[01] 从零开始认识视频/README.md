# 第一章 从零开始认识视频

视频已经成为我们日常生活中不可或缺的一部分，无论是电视、电影、互联网还是手机等，视频都随处可见。视频文件一般至少由视频轨以及音轨构成。本章将介绍视频轨的基本构成，包括色彩，采样，帧率，扫描方式，编码等方面。这些都是影响最终视频画面的关键因素。同时，本章还将涉及到视频文件的结构，即如何将以上元素整合在一起构建一个完整的视频文件。通过深入了解这些内容，读者将能够更好地理解视频制作和编辑的基本原理，为后续的视频处理工作奠定坚实的基础。

## 颜色

视频文件中，颜色主要由色彩空间（color space）、色彩原色（color primaries）、传输特性（transfer characteristics）、矩阵系数（matrix coefficients）以及色彩范围（color range）定义。

### 色彩空间 color space

视频的色彩空间是指用来描述视频颜色的一套规则，也可以说是定义视频中颜色的系统。常见的视频色彩空间有 RGB、YUV 和 YCbCr 等。RGB 是指红绿蓝三原色，也就是我们常说的光源的色彩系统；而 YUV 和 YCbCr 是指亮度（Y）和色度（U、V 或者 Cb、Cr）三个分量组成的颜色系统，一般用于描述传输视频信号。在 YUV 和 YCbCr 中，亮度是视频图像中最重要的成分，因为它直接决定了视频画面的明暗度，而色度则描述颜色中的色调和饱和度。

### 色彩原色 color primaries

#### 色彩原色的概念

在色彩学中，色彩原色指的是无法通过任何其他颜色混合而得到的颜色。在不同的色彩空间系统中，有不同的原色组合。可以分为 “叠加型” 和 “消减型” 两种系统。“叠加型” 的颜色系统通过不同颜色的光（原色），在黑暗的背景上产生颜色，一般是以光源投射的形式出现，例如CRT。这套原色系统常被称为 “RGB色彩空间”，亦即由红（R）绿（G）蓝（B）所组合出的色彩系统。相对的，“消减型” 的色彩系统是通过从 “白” 光中消去不需要的光谱（原色）。一般来说这种系统在透明或者反射介质上产生颜色，例如印刷品使用的 CMY 或者 CMYK 色彩系统。由于视频是以发光的显示屏作为载体显示的，因此在这里只讨论 RGB 颜色系统。

#### LMS 与 XYZ 色彩空间

“原色”并不是物理学中的一个概念，而是一个由人类视觉系统决定的生物学概念。人眼视网膜上有两种对光敏感的细胞，视杆细胞和视锥细胞。其中前者虽然数量庞大，而且对光非常敏感，但是主要负责夜视力，颜色学里面基本忽略；后者敏感度较低（相比前者1个光子就可以产生响应，后者需要大概10个），但是却能区分颜色。具体来讲，不同的波长会使人眼中的三种锥状细胞对光的强度产生不同的反应，从而导致我们感受到不同的颜色。

<figure style="text-align:center">
    <img src="media/Cone-fundamentals-with-srgb-spectrum.svg" alt="Normalized response spectra of human cones">
    <figcaption>人类视锥细胞对单色光谱刺激的归一化反应光谱，波长为纳米。</figcaption>
</figure>

这三种细胞的归一化的频响曲线如上图。所谓频响（频率响应）频响指的是视锥细胞对各个波长的光的敏感度，也就是光的颜色对于视锥细胞的刺激能力。人眼中共有三种不同类型的视锥细胞，它们对光的波长的反应各不相同。具体来说：

- S型视锥细胞（short-wavelength cones，也称蓝色光感受器）对光的波长最短的部分做出反应，敏感于波长为紫色到蓝色的光；

- M型视锥细胞（middle-wavelength cones，也称绿色光感受器）对光的波长在中间部分做出反应，敏感于波长为绿色的光；
- L型视锥细胞（long-wavelength cones，也称红色光感受器）对光的波长最长的部分做出反应，敏感于波长为黄色到红色的光。

根据这个我们可以知道 假设每种细胞输出都是标量，那么我们要表示颜色也至少需要三个分量，三个原色。 然后直接用 L/M/S 细胞的输出的数值来表示颜色就已经用非负值表示所有人眼可以区分的颜色了。因此 LMS 颜色系统主要用于描述人类视网膜中的三种不同类型的视锥细胞对不同波长光的敏感度，它可以准确地描述人类视网膜中的颜色感知。在视觉心理学、医学等领域，LMS系统被广泛应用。

然而，在色彩科学中，人们更多地使用其他颜色空间，如 CIE XYZ 颜色空间。这是因为 CIE XYZ 颜色空间能够更好地描述光的亮度和色度，并且更符合色彩测量和色彩管理的需求。CIE XYZ 颜色空间是为标准化色彩测量和色彩管理而设计的，可以精确地计算不同颜色之间的差异和色彩变换，因此它在许多领域被广泛应用，如计算机图形学、印刷、电影制作等。

<figure style="text-align:center">
    <img src="media/CIE-XYZ-Color-Space.svg" alt="CIE XYZ color space">
    <figcaption>CIE XYZ 色彩空间</figcaption>
</figure>

XYZ 色彩空间是由三个假想的原色 X、Y、Z 定义的，所有可见的颜色都位于一个三维锥状区域内（见图CIE XYZ 色彩空间 (a)），选择这三种颜色是为了使所有可见的颜色都能被描述为纯正成分的总和（这个色彩空间分布于第一象限），其中 Y 成分对应于一个颜色的感知亮度或明度，它的原点是黑点（a）图中的 S，E 是表示中性（灰色）颜色的轴。如果将 RGB 色彩空间映射到 XYZ 空间则是如（b）图所示的一个立方体。

如前所述，XYZ 色彩空间的亮度沿 Y 轴增加，从位于坐标原点的黑点 S 开始（X=Y=Z=0）。色相与亮度无关。例如，白色是明亮的颜色，而灰色被认为是不太亮的白色。换句话说，白色和灰色的色度是一样的，而明度不同。因此在 XYZ 色彩空间中，色相与 Y 值无关。为了方便地描述相应的 "纯 "色相和饱和度，CIE系统还定义了三个色度值：

$$x = \frac{X}{X+Y+Z}$$
$$y = \frac{Y}{X+Y+Z}$$
$$z = \frac{Z}{X+Y+Z}$$

其中 $x+y+z=1$。那么在归一化以后，表示某一个颜色只需要两个参数，比如 `x` 和 `y`，且 `x` 和 `y` 都是 `[0, 1]` 范围内，且由于 `z >= 0` ， `x + y <= 1`。那么上述的公式就描述了从 X、Y、Z 坐标系到三维平面 $X+Y+Z=1$ 的中心投影，其中原点 S 是投影中心。如下图所示：

<figure style="text-align:center">
    <img src="media/CIE-X-Y-Chromaticity-Diagram.svg" alt="CIE x, y chromaticity diagram">
    <figcaption>CIE x, y 色度图</figcaption>
</figure>
因此，对于任意的 XYZ 空间中的色点 $A=(X_a, Y_a, Z_a)$，相应的色度坐标 $a=(x_a, y_a, z_a)$ 是通过将线 $\bar{SA}$ 与  $X+Y+Z=1$ 相交得到的。那么最终 x,y 色度图只需要去除 $Z$ 分量 $z_a$ 即可得到，而这个结果就是著名的马蹄形 CIE x, y 色度分布图（见图 (c)）。马蹄形的区域里面表示着所有可见的颜色，其中上边沿一圈是各种波长的单色光对应的点。

如上图所示 RGB 三种颜色就是色彩原色（color primaries）由这三个点构成的三角形内的色度都可以用三原色的不同配比组成。同理，CMY 三原色框选出来的三角形区域中的颜色也可以用这三原色通过该不同配比表示。这是由颜色的可线性叠加的性质造成的，也就是说任意从马蹄形区域中选三个不共线的点，就可以做三原色，表示三点框出来的三角形内的所有颜色。所以三原色是不唯一的。

#### 视频中的色彩原色

由于 CIE XYZ 色彩空间包括了人类视觉系统可以看到的所有颜色，因此在视频标准中使用到的色彩空间也可以在 CIE x,y 色度图中找到对应的范围。

##### Rec. 601 标准

<figure style="text-align:center">
    <img src="media/CIExy1931_Rec_601.svg" alt="Rec. 601 chromaticity diagram">
    <figcaption>Rec. 601 色度图 625线（PAL和SECAM）显示为黑色；525线（NTSC SMPTE C primaries）显示为白色</figcaption>
</figure>
**Rec. 601** 标准，也就是标清 SDTV 用的颜色空间。可以看到，这个标准下，有两组原色，黑色框的顶点是 PAL 制式的原色，而白色框的顶点为 NTSC 制式的原色。对于制作 Rip 来说这个标准通常只会在 DVD 介质遇到。对于动画来说，特别是日本动画，一般是 NTSC 的标准。（注：这里的 NTSC 用的色域是由 Rec. 601 定义的，与下文 Rec. 709 用的 *primaries* 是一致的。但不同于我们一般说的 NTSC 1953 色域，NTSC 1953 要更古老。）

##### Rec. 709 标准

<figure style="text-align:center">
    <img src="media/CIExy1931_Rec_709.svg" alt="Rec. 709 chromaticity diagram">
    <figcaption>Rec. 709 色度图</figcaption>
</figure>
**Rec. 709** 标准，高清 HDTV 用的颜色空间。他的色彩范围如图所示。HDTV 和 SDTV 是这样判断的：

```python
if width <= 1024 and height <= 576:
  SDTV = True
elif width <= 2048 and height <= 1536:
  HDTV = True
else:
  UHD = True
```

这里是个比较奇怪的点，HD 的定义是 1024 长 **或者** 576 高以上的，两个条件满足一个即可。也就是 480p 的 DVD 是 SD，用 601 标准；BD 里面 720p 或者 1080p 是HD，（1080p 又称作 FHD full HD）用 709 标准。 之所以只规定宽和高中的一个，是考虑电影的黑框
1280 宽的电影，由于长宽比超过 16:9，高度一般不足 576。切记不是必须 1024x576 或者以上才算 HD。

##### Rec. 2020 标准

<figure style="text-align:center">
    <img src="media/CIExy1931_Rec_2020.svg" alt="Rec. 2020 chromaticity diagram">
    <figcaption>Rec. 2020 色度图</figcaption>
</figure>
**Rec. 2020** 标准，超高清 UHDTV使用的颜色空间。

如上文所述：只要是 2048 宽或者 1536 高以上，就可以判断为 UHD。Rec. 2020 这个框就明显大得多了，覆盖了更大的区域。不过可惜还没有多少电视能真的完全覆盖这个区域。



不同的标准色彩原色不同，特别是 Rec. 601 本身就有两种，实际运用的时候记得小心区别。由于 Rec. 2020 的覆盖面积很大，导致事实上基本都用 P3 而不是 Rec. 2020，然而 UHD 的标准还是 Rec. 2020。

此外，因为 XYZ 是线性空间，所以不同 *primaries* 之间可以线性映射，以保证在不同设备下颜色的一致性。

#### 白点

实际的 *primaries* 是个四元组，除了三个顶点（原色）的 x,y 坐标之外，还需要指定白点的位置。 形象地说，不同光照下颜色是不同的，而表示着光照条件的就是白点。白点有着不同的标准，比如 E 系列标准照明体，是频谱内全是平的，虽然理想，但是你现实中看电视绝对不是这种光照条件。因此多数用的 D 系列 模拟日光下的情况。日光 --> 黑体辐射谱。色温就是黑体的温度。D 系列是不同温度的黑体辐射的频谱。例如常用的 D65 标准源是指在黑体辐射温度为6504K时，发出的光谱。

### 传输特性 transfer characteristics

前面讨论的 RGB 颜色其实都是用 `[0, 1]` 范围内的实数表示的。计算机显然不能真的表示实数，虽然浮点数可以近似表示实数，但是用浮点数来表示视频中的颜色效率非常低，我们还是希望用整数来表示。因此需要将连续的实数转化为整数，这个步骤被称为量化（quantization）。

这个步骤看起来似乎并不是非常复杂，假设人类可以分辨的最低亮度是 1，那么我们直接记录它的倍数来表示更高的亮度。为了提高精度我们甚至可以假设这个能分辨的最低亮度是 10。像这样的量化，我们称之为*线性量化*。对应的颜色一般叫*线性光颜色*，表示数值与光的能量成正比（线性）关系。

不过实际用起来有一个问题，就是人眼可以区分的亮度范围很广，以 8bit 视频为例，如果在这么广的范围平分 256 个区间量化为对应的数字，会导致高亮度的区域，相邻亮度级之间区别不大甚至根本没有。低亮度区域则区别过大，丢失了很多本来可以区分的亮度级。换句话说人眼对亮度的感受并不是线性的。

所以为了更加好的利用可用的数值范围，我们使用非线性量化，低亮度区域相邻数值间的实际亮度差较低，高亮度的则大得多。
在这里描述量化后的数值与实际光的能量之间的对应关系函数就叫 *transfer*。这个词或许大家觉得陌生， *transfer* 在 DSP (Digital signal processing) 是传递（函数）的意思，是一个系统的输入和输出之间的数学关系，它描述了输入信号经过系统后产生的输出信号的变化规律。

熟悉视频的读者可能会对 gamma 校正这个名词更熟悉。早期这种线性与非线性光的映射操作叫 gamma 校正。这是因为在显像管电视时代，输入电压跟输出的亮度之间的关系大概是个 $Out = In^{gamma}$ 的关系。当时使用的 gamma 值大约为2.4，随后工程师发现这样的输入输出关系基本上与人眼感受到的亮度是对应的。所以现在的 transfer 会使用类似的公式，但是具体的参数有所不同。

综上所述线性光与非线性光之间的桥梁就是传输特性。

一般我们做视频处理都是直接用非线性光做，这才是一般大家提的 RGB。为了严谨起见，如果需要特地区分，非线性量化会在对应变量加上 `'` 表示。比如 `R'G'B'` 表示非线性量化的 RGB，特点是每个数值之间对人言来说亮度差异几乎一致。而不带角标的是线性的，跟物理上的能量直接对应的。

### 矩阵系数 matrix coefficients

视频的 matrix coefficients（矩阵系数）是指在将 RGB（红绿蓝）颜色空间转换为 YUV（亮度、色度）颜色空间时，所使用的转换矩阵系数。

#### YUV 色彩空间

在介绍矩阵系数之前，还需要引出 YUV 色彩空间的概念。

<figure style="text-align:center">
    <img src="media/YUV-sc-dot-grid.png" alt="color assimilation">
    <figcaption>视错觉演示图</figcaption>
</figure>

当你远看这张图时，你会发现它看起来像是一张彩色的图片，但当你放大这张图片你就会发现，这张图整体为黑白色，只是在关键的位置加了非常零星的彩色点表示对应区域的颜色。尽管这个点间距极大，就算放大看大图，人眼依然会倾向于感觉对应的整片区域都是那个颜色。像这样的视错觉现象被称为色彩同化。原因是，人眼对亮度的分辨率异常敏感，相比之下，对颜色的分辨率就低得多。

如果我们要在有限的尺寸内压缩一张图片 / 视频，它的颜色信息就相对不如亮度信息重要。因此在视频编码时，考虑到数据压缩，我们选择用一种可以分离开亮度和“色度”（或者说颜色）的颜色编码。通过分离亮度和色度信息，就可以尽可能地去保留前者，有选择的通过损失后者的方法做到提高数据的利用率。换句话说就是在保证人能够观察到相同内容的前提下，减少数据量。这个编码就是 YUV，也有叫 YCbCr。

#### YUV 与 RGB

以 Rec. 709 标准为例，是这样一个转换方式:

$$
\begin{bmatrix}
   Y' \\\
   U \\\
   V \\\
\end{bmatrix} = 
\begin{bmatrix}
   0.2126 & 0.7152 & 0.0722 \\\
   -0.114572 & 0.385428 & 0.5 \\\
   0.5 & -0.454153 & -0.045847 \\\
\end{bmatrix}
\begin{bmatrix}
   R' \\\
   G' \\\
   B' \\\
\end{bmatrix}
$$
这个公式的含义是 YUV 可以通过 RGB 做一个线性操作得到。换句话说，YUV 也是另一种三“原色”，只不过 YUV 都不对应真实的颜色。Y 表示的人眼可见的亮度信息，而 UV 则表示纯颜色信息。 YUV 也可以通过先行操作转换到 RGB：

$$
\begin{bmatrix}
   R' \\\
   G' \\\
   B' \\\
\end{bmatrix} = 
\begin{bmatrix}
   1 & 0 & 1.5748 \\\
   1 & -0.187324 & -0.468124 \\\
   1 & 1.8556 & 0 \\\
\end{bmatrix}
\begin{bmatrix}
   Y' \\\
   U \\\
   V \\\
\end{bmatrix}
$$
前文介绍过， RGB 都是 [0, 1] 之间的实数，那么根据 Y'UV 转换到 R'G'B' 的公式可以发现：Y'UV 的数值范围分别是 [0, 1] [-0.5, 0.5] [-0.5, 0.5]。对上述公式稍加变换即可得到如下的内容：

$$
\begin{aligned}
Y' &= 0.2126R' + 0.7152G' + 0.0722B' \\\
U &= 0.5390(B' - Y') \\\
V &= 0.6350(R' - Y')
\end{aligned}
$$
Y' 直接用 R'G'B' 表示，UV 则换了一种等价的表示方式。这里 U 和 V 分别是 B' / R' 与 Y' 的差，最后乘一个系数使得最后范围是 [-0.5, 0.5]。因此 UV 这里也叫色差信号，分别用 U/Cb 表示（B'-Y'），和 V/Cr 表示（R'-Y'）。

注：在上述表达中，仅出现了 `Y'` 并没有出现 `U'` 或者 `V'`。这是因为 Y 是亮度，非线性量化的物理值，但 UV 在理论上是与亮度无关的，无需经过 gamma 校正。

#### matrix

可以看到 YUV 和 RGB 互转是通过一个矩阵乘法进行的，这个矩阵就叫 **matrix** 。不同的标准转换矩阵不同，Rec. 601 和 Rec. 709 的差异尤其明显，当你使用了错误的转换矩阵就会发生偏色。RGB 转 YUV 与 YUV 转 RGB 的俩个矩阵互为逆矩阵，所以一般只指定一个，用 **matrix** 统称。

### 色彩范围 color range

在前文中提到的 Y'UV 均为浮点数，但是视频却是以整数表示的，色彩范围就是浮点量化成整数时候所用的整数的范围。

以8-bit视频为例，Y 的值以 0-255 对应 [0, 1]。这样的对应关系被称为 `full range` 或者 `pc range`。而视频中更为常用被称为 `limited range` 的色彩范围。

> limited range 还有一个叫法叫 studio range，但在 VS 里面一般是统一的 limited range

8-bit为例，在 `limited range` 中 Y 的实际范围是 [16, 235]， UV 的范围是 [16, 240]。其中 128 是 UV 的中点 0，16 表示 -0.5，240 表示 0.5。

#### limited range 的意义

有些读者可能会在这里产生疑问：我们用非线性量化是为了尽可能高效利用数值的范围，但这里却“浪费了”最高和最低的两段数字。

在低端不使用的 16 个数字，学名叫 `footroom`，高的那段叫 `headroom`

> HDI 标准中确实使用这部分不能用的数字表示sync信号

不使用这两段数字的主要理由如下：

1. 一个实际的传感器输出的信号必然伴随着随机噪声（白噪声），这些噪声（能量）可正可负。如果我们要求输出的 0 点就是 0，就意味着正噪声可以表示，负噪声一律变成了 0（截断）。这意味着平均的噪声不再是 0，0 点实际偏高了。因此 `footroom` 是必须保留的。
2. 在数字信号处理过程中，很多处理算法是不能保证输出的范围跟输入匹配的。很有可能在过程中发生 `overshoot`（过冲，高于输入上限）和 `undershoot`（低于输入下限）。对于这种情况，通常只需要使用 `clamp`，将超过上下限的数值钳位到对应的极值。但是很明显的，这是一个非线性的操作，这就会引入额外的噪声。`footroom` 和 `headroom` 的意义在于可以连续多个处理后一次性做这个 `clamp` 操作，以此避免多次引入非线性噪声。（这个操作可以近似理解为做四则运算的时候，多保留几位有效数字，最后再通过一次四舍五入得到需要的精度，而不是每做一步都做一次四舍五入）

#### Range 的换算

虽然 YUV 视频一般是用 `limited range`，但是也有例外情况是 `full range`。以下是一个基于 8-bit 视频的公式：

$$Y_{limited} = round({219\over255}*Y_{full}) +16$$

当然，在实际操作中在进行转换时应当使用更高的精度，那么在转换过程中出现的四舍五入导致的误差才可以被忽略。在 VS 的操作中可以将 8-bit 源先转换成 16-bit 源再进行后续处理。

对于不同位深度的视频，以 8-bit 转 10-bit 为例：8-bit limited Y [16,235], UV [16,240]，转换到 10-bit limited，Y就是 [16⋅4, 235⋅4] 或者说 [64, 940]，UV 则是 [64, 960]。

> full 和 limited 在提高位宽 k bits 的时候的行为是不同的，limited 直接乘以 2^k 即可，但是 full 则要做一个完整的重映射，比如 8bit full Y 到 10bit full Y，需要做一个 `1023 * Y8 / 255` 的映射，不是直接乘以4了。

UV 从 full range 转换到 limited range 有一个额外的注意点：limited range U/V 有奇数个数，正好 0 点两边是对称的，full range U/V 一共有 256 个数值，刨去 0 之外不是偶数，所以左右不对称了。因此根据选择，这个转换可以拥有两个相似但不等价的公式。而为了避免这个情况，可以在浮点数下运算，再四舍五入。

> full range UV 的时候有两种转换方式，因为 128 两侧的数字不一样多，但是 limited 的时候两侧是一样多的，浮点转回去的时候 就是 224*U + 16.

### 总结

这里稍微总结一下关键的必须理解的几个有关颜色概念：

1. 色彩原色（color primaries）：RGB里面的三原色和白点的位置，决定了可表示的颜色的范围
2. 传输特性（transfer characteristics）：线性光和非线性光之间的纽带，形式为 $Out = In^{gamma}$ ，所以传统上也叫 gamma 校正。
3. 矩阵系数（matrix coefficients）：视频编码实际用的 YUV 颜色与显示用的 RGB 之间的转换矩阵。
4. 色彩范围（color range）：YUV 编码时每个分量所使用的亮度和颜色取值的范围。

不同的视频标准（比如 SD 的 Rec. 601 和 HD 的 Rec. 709，UHD 使用的 Rec. 2020）会分别指定 primaries / transfer / matrix，我们在做相应的转换的时候可能需要指定所用的标准。
